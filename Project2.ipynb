{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Packages and dataset load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm\n",
    "# import dataframe_image as df___i\n",
    "\n",
    "color = {\"granate\":\"#BA4A00\",\n",
    "         \"amarillo\":\"#F5B041\",\n",
    "         \"verde\":\"#148F77\",\n",
    "         \"blue\":\"#0051A2\",\n",
    "         \"red\": \"#DD1717\"}\n",
    "color_palette = [color[\"blue\"], 'darkorchid', color['verde'], color['amarillo'],'gray', 'cornflowerblue', color['red']]\n",
    "sb.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Dry_Bean_Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Auxiliar functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_creator(models_names: list, columns_names: list, k1: int):\n",
    "    header = pd.MultiIndex.from_product([models_names, columns_names])\n",
    "    df = pd.DataFrame(columns=header)\n",
    "    df['KFold'] = np.arange(1, k1+1)\n",
    "    df.set_index('KFold', inplace=True)\n",
    "    return df\n",
    "\n",
    "def twolevelcv(X: np.array, y: np.array, k1: int, k2: int, models: list, params: dict, rs: int):\n",
    "    \"\"\"Allows to compute two level crossvalidation.\n",
    "\n",
    "    Args:\n",
    "        X (np.array): Features (numeric)\n",
    "        y (np.array): Class (objective variable)\n",
    "        k1 (int): Nº of outer folds\n",
    "        k2 (int): Nº of inner folds\n",
    "        models (list): List of models for comparison\n",
    "        params (dict): Dictionary including the set of parameters. In this case we only tune 1 parameter per model.\n",
    "        rs (int): Random state\n",
    "    Returns:\n",
    "        df: Dataframe\n",
    "    \"\"\"\n",
    "    test_error_dict = {}\n",
    "    k = 0\n",
    "    names = [type(m).__name__ for m in models]\n",
    "    col_names = ['Param. Value', 'Error']\n",
    "    df = dataset_creator(names, col_names, k1)\n",
    "    kf1 = StratifiedKFold(k1, shuffle = True, random_state=rs)\n",
    "    # first level split\n",
    "    for train_idx1, test_idx1 in kf1.split(X, y):\n",
    "        k += 1\n",
    "        kf2 = StratifiedKFold(k2, shuffle = True, random_state=rs)\n",
    "        print(f'Computing KFold {k}/{k1}...')\n",
    "        # second level split\n",
    "        for train_idx2, test_idx2 in tqdm(kf2.split(X[train_idx1, :], y[train_idx1]), total = k2):\n",
    "            X_train = X[train_idx2, :]\n",
    "            y_train = y[train_idx2]\n",
    "            X_test = X[test_idx2, :]\n",
    "            y_test = y[test_idx2]\n",
    "            for name, model in zip(names, models):\n",
    "                if name != 'DummyClassifier':\n",
    "                    pname = list(params[name].keys())[0]\n",
    "                    error_test = []\n",
    "                    for p_ in params[name][pname]:\n",
    "                        pdict = {pname: p_}\n",
    "                        model = model.set_params(**pdict)\n",
    "                        # train the model\n",
    "                        model.fit(X_train, y_train)\n",
    "                        # evaluate performance\n",
    "                        pred2_test = model.predict(X_test)\n",
    "                        error_test.append(np.sum(pred2_test != y_test)/ y_test.shape[0])\n",
    "                    min_param = params[name][pname][np.argmin(error_test)]\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "                    pred2_test = model.predict(X_test)\n",
    "                    error_test = np.sum(pred2_test != y_test)/ y_test.shape[0]\n",
    "                    min_param = np.NaN\n",
    "                df.loc(axis = 1)[name, 'Error'][k] = np.min(error_test)\n",
    "                df.loc(axis = 1)[name, 'Param. Value'][k] = min_param\n",
    "    return df, test_idx1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad43814",
   "metadata": {},
   "source": [
    "# **1 - Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "· NUMBER OF FEATURES: 16\n",
      "\n",
      "· FEATURES:\n",
      " ['Area' 'Perimeter' 'MajorAxisLength' 'MinorAxisLength' 'AspectRation'\n",
      " 'Eccentricity' 'ConvexArea' 'EquivDiameter' 'Extent' 'Solidity'\n",
      " 'roundness' 'Compactness' 'ShapeFactor1' 'ShapeFactor2' 'ShapeFactor3'\n",
      " 'ShapeFactor4']\n",
      "\n",
      "· NUMBER OF DATA POINTS: 13611\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns.values\n",
    "X = df.drop(columns='Class').values\n",
    "y = df['roundness']\n",
    "\n",
    "\n",
    "print('· NUMBER OF FEATURES:', X.shape[1])\n",
    "print('\\n· FEATURES:\\n', columns[:-1])\n",
    "print('\\n· NUMBER OF DATA POINTS:', X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part A. *Linear regression.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part B. *Other models. Evaluation.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cad43814",
   "metadata": {},
   "source": [
    "# **2 - Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying object without editing the original\n",
    "df_ = df.copy(deep=True)\n",
    "# Doing this we can choose to use outliers filter or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "· NUMBER OF FEATURES: 16\n",
      "\n",
      "· FEATURES: ['Area' 'Perimeter' 'MajorAxisLength' 'MinorAxisLength' 'AspectRation'\n",
      " 'Eccentricity' 'ConvexArea' 'EquivDiameter' 'Extent' 'Solidity'\n",
      " 'roundness' 'Compactness' 'ShapeFactor1' 'ShapeFactor2' 'ShapeFactor3'\n",
      " 'ShapeFactor4']\n",
      "\n",
      "· NUMBER OF DATA POINTS: 13611\n",
      "\n",
      "· CLASSES: ['SEKER' 'BARBUNYA' 'BOMBAY' 'CALI' 'HOROZ' 'SIRA' 'DERMASON']\n",
      "\n",
      "· NUMBER OF CLASSES: 7\n"
     ]
    }
   ],
   "source": [
    "columns = df_.columns.values\n",
    "X = df_.drop(columns='Class').values\n",
    "y = df_['Class']\n",
    "le = LabelEncoder()\n",
    "y_ = le.fit_transform(y)\n",
    "classes = y.unique()\n",
    "\n",
    "print('· NUMBER OF FEATURES:', X.shape[1])\n",
    "print('\\n· FEATURES:', columns[:-1])\n",
    "print('\\n· NUMBER OF DATA POINTS:', X.shape[0])\n",
    "print('\\n· CLASSES:', classes)\n",
    "print('\\n· NUMBER OF CLASSES:', len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Transformations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered outliers: 298\n"
     ]
    }
   ],
   "source": [
    "Threshold_ = 3\n",
    "outlier_index = []\n",
    "df_ = pd.DataFrame(columns=df.columns)\n",
    "index = 0\n",
    "for K in classes:\n",
    "    outlier_index = []\n",
    "    a = df.loc[df[\"Class\"] == K]\n",
    "    value = a.drop(columns='Class').values\n",
    "    for j in range(16):\n",
    "        std = np.std(value[:, j])\n",
    "        mean = np.mean(value[:, j])\n",
    "        for i in range(value[:, j].shape[0]):\n",
    "            if (value[i, j] - mean) / std > Threshold_:\n",
    "                outlier_index.append(i + index)\n",
    "    index = i + index + 1\n",
    "    outlier_index = np.unique(outlier_index)\n",
    "    a = a.drop(outlier_index)\n",
    "    df_ = pd.concat([df_,a])\n",
    "df_.reset_index(drop=True, inplace=True)\n",
    "print(f'Filtered outliers: {df.shape[0] - df_.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarization of the dataset\n",
    "sc = StandardScaler()\n",
    "X_stdz = sc.fit_transform(X)\n",
    "df_stdz = pd.DataFrame(columns = columns[:-1], data = X_stdz)\n",
    "df_stdz['Class'] = y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Logistic regression *vs.* Neural Network *vs.* Baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "random_state = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression(multi_class='multinomial', solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# # evaluate the model and collect the scores\n",
    "# n_scores = cross_val_score(model, X_stdz, y_, scoring = 'accuracy', cv=cv, n_jobs=-1)\n",
    "# # report the model performance\n",
    "# print('Mean Accuracy: %.3f (+-%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3 Cross-Validation table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 1/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 2/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 3/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 4/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 5/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 6/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 7/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 8/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 9/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 10/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.80s/it]\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params['LogisticRegression'] = {'C': [0.05, 0.07, 0.08, 0.09]}\n",
    "params['DummyClassifier'] = [None]\n",
    "params['MLPClassifier'] = {'hidden_layer_sizes': [(8,), (16,), (20,)]}\n",
    "models = [LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state= random_state),\n",
    "        DummyClassifier(strategy='most_frequent', random_state=random_state),\n",
    "        MLPClassifier(solver='adam', activation='logistic', alpha=1e-4, random_state=random_state, max_iter=1000, \n",
    "        early_stopping=True, validation_fraction=0.2, warm_start=True, verbose=False, learning_rate ='adaptive', learning_rate_init=0.01)]\n",
    "k1 = 10\n",
    "k2 = 10\n",
    "Table, test_set_outer = twolevelcv(X = X_stdz, y = y_, k1 = k1, k2 = k2, models = models, params = params, rs = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">LogisticRegression</th>\n",
       "      <th colspan=\"2\" halign=\"left\">DummyClassifier</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MLPClassifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Param. Value</th>\n",
       "      <th>Error</th>\n",
       "      <th>Param. Value</th>\n",
       "      <th>Error</th>\n",
       "      <th>Param. Value</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.042484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788399</td>\n",
       "      <td>(16,)</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.036735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78449</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.035102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.036735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78449</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.034286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.036735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78449</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.035918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.036735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78449</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.035918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.037551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790204</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.040816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.037551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790204</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790204</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.041633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790204</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.042449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.044082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788571</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.044082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LogisticRegression           DummyClassifier           MLPClassifier  \\\n",
       "            Param. Value     Error    Param. Value     Error  Param. Value   \n",
       "KFold                                                                        \n",
       "1                   0.09  0.042484             NaN  0.788399         (16,)   \n",
       "2                   0.08  0.036735             NaN   0.78449          (8,)   \n",
       "3                   0.08  0.036735             NaN   0.78449          (8,)   \n",
       "4                   0.08  0.036735             NaN   0.78449          (8,)   \n",
       "5                   0.08  0.036735             NaN   0.78449          (8,)   \n",
       "6                   0.07  0.037551             NaN  0.790204          (8,)   \n",
       "7                   0.07  0.037551             NaN  0.790204          (8,)   \n",
       "8                   0.07  0.034286             NaN  0.790204          (8,)   \n",
       "9                   0.07  0.034286             NaN  0.790204          (8,)   \n",
       "10                  0.07  0.044082             NaN  0.788571          (8,)   \n",
       "\n",
       "                 \n",
       "          Error  \n",
       "KFold            \n",
       "1      0.039216  \n",
       "2      0.035102  \n",
       "3      0.034286  \n",
       "4      0.035918  \n",
       "5      0.035918  \n",
       "6      0.040816  \n",
       "7          0.04  \n",
       "8      0.041633  \n",
       "9      0.042449  \n",
       "10     0.044082  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table = Table.round(3)\n",
    "Table.to_csv(r'Results\\Table_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1361,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_outer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.4 Stadistical Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def McNemar(models: list, X: np.array, y: np.array, k1: int, rs: int):\n",
    "    kf1 = StratifiedKFold(k1, shuffle = True, random_state=rs)\n",
    "    k = 0\n",
    "    # setting up all the possible combinations between the different models\n",
    "    matrix = dict.fromkeys(combinations(range(len(models)), 2))\n",
    "    for train_idx, test_idx in kf1.split(X, y):\n",
    "        test_size = test_idx.shape[0]\n",
    "        yABC = np.empty(shape=(len(models), test_size))\n",
    "        for i, model in enumerate(models):\n",
    "            model.fit(X[train_idx,:], y[train_idx])\n",
    "            y_pred = model.predict(X[test_idx, :])\n",
    "            yABC[i, :] = 1*(y_pred == y[test_idx])\n",
    "        for j in list(matrix.keys()):\n",
    "            if k == 0:\n",
    "                matrix[j] = np.empty(shape=(k1, 4))\n",
    "            n11 = np.sum(yABC[j[0],:]*yABC[j[1],:])\n",
    "            n12 = np.sum(yABC[j[0],:]*(1-yABC[j[1],:]))\n",
    "            n21 = np.sum(yABC[j[1],:]*(1-yABC[j[0],:]))\n",
    "            n22 = np.sum((1-yABC[0,:])*(1-yABC[1,:]))\n",
    "            matrix[j][k] = np.array([n11, n12, n21, n22])\n",
    "        k+=1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1\n",
    "models = [LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state= random_state, C = 0.07),\n",
    "        DummyClassifier(strategy='most_frequent', random_state=random_state),\n",
    "        MLPClassifier(solver='adam', activation='logistic', alpha=1e-4, random_state=random_state, max_iter=1000, hidden_layer_sizes=(8, ),\n",
    "        early_stopping=True, validation_fraction=0.2, warm_start=True, verbose=False, learning_rate ='adaptive', learning_rate_init=0.01)]\n",
    "k1 = 10\n",
    "m = McNemar(models, X_stdz[test_set_outer, :], y_[test_set_outer], k1, rs = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the matrix with shape (3: number of models, 10: nº of k-folds, 4: matrix shape)\n",
    "\n",
    "The matrix is squeezed so we have:\n",
    "$$\\begin{bmatrix}\n",
    " n_{11}    & n_{12}  \\\\\n",
    " n_{21}    & n_{22}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Here is $[ n_{11}, n_{12}, n_{21}, n_{22} ]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0:$ Model A has the same performarnce as model B \n",
    "\n",
    "$H_1:$ Model A and model B has different performance\n",
    "\n",
    "small p_value-> we discard H0 -> Model A and Model B have different performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we set:\n",
    "\n",
    "**Model 0**: LR\n",
    "\n",
    "**Model 1**: Baseline\n",
    "\n",
    "**Model 2**: MLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***P-Values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "combs = list(combinations(range(len(models)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "pv_dict = dict.fromkeys(combs)\n",
    "for j in combs:\n",
    "    vals = m[j][:, 1:3]\n",
    "    pv_dict[j] = [binom.cdf(min(vals[i]), n = sum(vals[i]), p = 1/2) for i in range(len(vals))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "McNemar_pv = pd.DataFrame(columns = combs, index = range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for n in pv_dict.values():\n",
    "    print(f'{combs[i]}')\n",
    "    for j, k in enumerate(n):\n",
    "        McNemar_pv[combs[i]][j] = \"{:.3e}\".format(k)\n",
    "        print(\"{:.3e}\".format(k))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "McNemar_pv.to_csv('McNemar_pv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcs(mat: np.array):\n",
    "    \"\"\"Calculate f y g from a McNemar Matrix\n",
    "\n",
    "    Args:\n",
    "        matrix (np.array): McNemar matrix from one K-fold\n",
    "\n",
    "    Returns:\n",
    "        _type_: f and g\n",
    "    \"\"\"\n",
    "    n = mat.sum()\n",
    "    n12 = mat[1]\n",
    "    n21 = mat[2]\n",
    "    E_th = (n12 - n21)/n \n",
    "    Q = (n**2 (n+1)*(E_th +1)*(1-E_th)) / (n*(n12 +n21) - (n12 - n21)**2)\n",
    "    f = (Q-1)*(E_th+1)/2\n",
    "    g = (Q-1)*(1-E_th)/2\n",
    "    return f, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval(f,g):\n",
    "    beta.ppf\n",
    "    return theta_L, theta_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34., 92.,  2.,  9.],\n",
       "       [34., 93.,  1.,  8.],\n",
       "       [32., 92.,  3.,  9.],\n",
       "       [35., 91.,  0., 10.],\n",
       "       [34., 98.,  1.,  3.],\n",
       "       [34., 84.,  1., 17.],\n",
       "       [31., 93.,  5.,  7.],\n",
       "       [33., 96.,  3.,  4.],\n",
       "       [31., 93.,  5.,  7.],\n",
       "       [32., 94.,  4.,  6.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[combs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.5 Train logistic regression model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the fourth exercise do we have to repeat the parameter selection process or can just go ahead with the best parameter selection for each model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2f6c66c89ad4c8419177551668bc68e5b63841305411eba2146a4407b0a55c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
