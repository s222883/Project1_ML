{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Packages and dataset load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm\n",
    "# import dataframe_image as df___i\n",
    "\n",
    "color = {\"granate\":\"#BA4A00\",\n",
    "         \"amarillo\":\"#F5B041\",\n",
    "         \"verde\":\"#148F77\",\n",
    "         \"blue\":\"#0051A2\",\n",
    "         \"red\": \"#DD1717\"}\n",
    "color_palette = [color[\"blue\"], 'darkorchid', color['verde'], color['amarillo'],'gray', 'cornflowerblue', color['red']]\n",
    "sb.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Dry_Bean_Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Auxiliar functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_creator(models_names: list, columns_names: list, k1: int):\n",
    "    header = pd.MultiIndex.from_product([models_names, columns_names])\n",
    "    df = pd.DataFrame(columns=header)\n",
    "    df['KFold'] = np.arange(1, k1+1)\n",
    "    df.set_index('KFold', inplace=True)\n",
    "    return df\n",
    "\n",
    "def twolevelcv(X: np.array, y: np.array, k1: int, k2: int, models: list, params: dict, rs: int):\n",
    "    \"\"\"Allows to compute two level crossvalidation.\n",
    "\n",
    "    Args:\n",
    "        X (np.array): Features (numeric)\n",
    "        y (np.array): Class (objective variable)\n",
    "        k1 (int): Nº of outer folds\n",
    "        k2 (int): Nº of inner folds\n",
    "        models (list): List of models for comparison\n",
    "        params (dict): Dictionary including the set of parameters. In this case we only tune 1 parameter per model.\n",
    "        rs (int): Random state\n",
    "    Returns:\n",
    "        df: Dataframe\n",
    "    \"\"\"\n",
    "    test_error_dict = {}\n",
    "    k = 0\n",
    "    names = [type(m).__name__ for m in models]\n",
    "    col_names = ['Param. Value', 'Error']\n",
    "    df = dataset_creator(names, col_names, k1)\n",
    "    kf1 = StratifiedKFold(k1, shuffle = True, random_state=rs)\n",
    "    # first level split\n",
    "    for train_idx1, test_idx1 in kf1.split(X, y):\n",
    "        k += 1\n",
    "        kf2 = StratifiedKFold(k2, shuffle = True, random_state=rs)\n",
    "        print(f'Computing KFold {k}/{k1}...')\n",
    "        # second level split\n",
    "        for train_idx2, test_idx2 in tqdm(kf2.split(X[train_idx1, :], y[train_idx1]), total = k2):\n",
    "            X_train = X[train_idx2, :]\n",
    "            y_train = y[train_idx2]\n",
    "            X_test = X[test_idx2, :]\n",
    "            y_test = y[test_idx2]\n",
    "            for name, model in zip(names, models):\n",
    "                if name != 'DummyClassifier':\n",
    "                    pname = list(params[name].keys())[0]\n",
    "                    error_test = []\n",
    "                    for p_ in params[name][pname]:\n",
    "                        pdict = {pname: p_}\n",
    "                        model = model.set_params(**pdict)\n",
    "                        # train the model\n",
    "                        model.fit(X_train, y_train)\n",
    "                        # evaluate performance\n",
    "                        pred2_test = model.predict(X_test)\n",
    "                        error_test.append(np.sum(pred2_test != y_test)/ y_test.shape[0])\n",
    "                    min_param = params[name][pname][np.argmin(error_test)]\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "                    pred2_test = model.predict(X_test)\n",
    "                    error_test = np.sum(pred2_test != y_test)/ y_test.shape[0]\n",
    "                    min_param = np.NaN\n",
    "                df.loc(axis = 1)[name, 'Error'][k] = np.min(error_test)\n",
    "                df.loc(axis = 1)[name, 'Param. Value'][k] = min_param\n",
    "    return df, test_idx1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad43814",
   "metadata": {},
   "source": [
    "# **1 - Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "· NUMBER OF FEATURES: 16\n",
      "\n",
      "· FEATURES:\n",
      " ['Area' 'Perimeter' 'MajorAxisLength' 'MinorAxisLength' 'AspectRation'\n",
      " 'Eccentricity' 'ConvexArea' 'EquivDiameter' 'Extent' 'Solidity'\n",
      " 'roundness' 'Compactness' 'ShapeFactor1' 'ShapeFactor2' 'ShapeFactor3'\n",
      " 'ShapeFactor4']\n",
      "\n",
      "· NUMBER OF DATA POINTS: 13611\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns.values\n",
    "X = df.drop(columns='Class').values\n",
    "y = df['roundness']\n",
    "\n",
    "\n",
    "print('· NUMBER OF FEATURES:', X.shape[1])\n",
    "print('\\n· FEATURES:\\n', columns[:-1])\n",
    "print('\\n· NUMBER OF DATA POINTS:', X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part A. *Linear regression.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part B. *Other models. Evaluation.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part A. *Linear regression.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part B. *Other models. Evaluation.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate training data x and label y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13611, 9)\n"
     ]
    }
   ],
   "source": [
    "label_feature = 'AspectRation'\n",
    "\n",
    "x = df.drop(columns=['Class', label_feature, 'MajorAxisLength', 'MinorAxisLength', \\\n",
    "                     'Compactness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', \\\n",
    "                    'ShapeFactor4']).values\n",
    "Class = df['Class']\n",
    "class_label = []\n",
    "dictionary = {\n",
    "    'SEKER': 0,\n",
    "    'BARBUNYA': 1,\n",
    "    'BOMBAY': 2, \n",
    "    'CALI': 3,\n",
    "    'HOROZ': 4,\n",
    "    'SIRA': 5,\n",
    "    'DERMASON': 6\n",
    "}\n",
    "for i in Class:\n",
    "    class_label.append(dictionary[i])\n",
    "\n",
    "class_label = np.array(class_label)\n",
    "x = np.array(x)\n",
    "x = np.insert(x, x.shape[1], class_label, axis=1)\n",
    "y = df[label_feature]\n",
    "y = np.array(y)\n",
    "y = y.reshape((-1,1))\n",
    "x = x.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "print(x.shape)\n",
    "# X = x\n",
    "N = x.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard = x - np.ones((N, 1))*x.mean(0)\n",
    "X_standard = X_standard*(1/np.std(X_standard,0))\n",
    "\n",
    "X = X_standard\n",
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0060303346\n"
     ]
    }
   ],
   "source": [
    "# import toolbox_02450\n",
    "from matplotlib.pyplot import figure, plot, xlabel, ylabel, legend, show\n",
    "import sklearn.linear_model as lm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Fit ordinary least squares regression model\n",
    "# model = lm.LinearRegression(fit_intercept=True)\n",
    "model = lm.Ridge(alpha = 1.0, fit_intercept=True)\n",
    "model = model.fit(X,y)\n",
    "# Compute model output:\n",
    "y_est = model.predict(X)\n",
    "loss = nn.MSELoss()(torch.from_numpy(y).to(device), torch.from_numpy(y_est).to(device))\n",
    "print(loss.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006003649539698801\n"
     ]
    }
   ],
   "source": [
    "class Linear_Regression():\n",
    "    def __init__(self, weight = 0.0) :\n",
    "        self.weight = weight\n",
    "        self.w = None\n",
    "    \n",
    "    def fit(self,  X: np.array, y: np.array):\n",
    "        x0 = np.ones((X.shape[0], 1))\n",
    "        X = np.concatenate((X,x0),axis=1)\n",
    "        X = np.matrix(X)\n",
    "        y = np.matrix(y)\n",
    "        w = np.matmul(X.T, X)\n",
    "        w = w + self.weight * np.eye(X.shape[1], X.shape[1])\n",
    "        w = w.I * (X.T * y)\n",
    "        self.w = w\n",
    "        return w\n",
    "    \n",
    "    def predict(self, X: np.array):\n",
    "        x0 = np.ones((X.shape[0], 1))\n",
    "        X = np.concatenate((X,x0),axis=1)\n",
    "        X = np.matrix(X)\n",
    "        y_pred = X * self.w\n",
    "        return y_pred\n",
    "\n",
    "model = Linear_Regression(0.0)\n",
    "w = model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "loss = nn.MSELoss()(torch.from_numpy(y).to(device), torch.from_numpy(y_pred).to(device))\n",
    "print(loss.cpu().detach().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.060845792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\karl\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([13611])) that is different to the input size (torch.Size([13611, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "model = DummyRegressor(strategy=\"mean\")\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "loss = nn.MSELoss()(torch.from_numpy(y).to(device), torch.from_numpy(y_pred).to(device))\n",
    "print(loss.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "(13611, 1)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.pylab import figure, plot, xlabel, ylabel, legend, ylim, show\n",
    "import sklearn.linear_model as lm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "print(\"device: \", device)\n",
    "\n",
    "class Neural_Net(nn.Module):\n",
    "    def __init__(self, num_input, num_output, num_hidden):\n",
    "        super(Neural_Net, self).__init__()\n",
    "        self.Net = nn.Sequential(\n",
    "            nn.Linear(num_input, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, num_output)\n",
    "        )\n",
    "        torch.nn.init.xavier_uniform_(self.Net[0].weight)\n",
    "        torch.nn.init.xavier_uniform_(self.Net[2].weight)\n",
    "        torch.nn.init.xavier_uniform_(self.Net[4].weight)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.Net(input)\n",
    "\n",
    "class ANN():\n",
    "    def __init__(self, num_input, num_output, num_hidden, max_iters):\n",
    "        self.num_input = num_input\n",
    "        self.num_output = num_output\n",
    "        self.num_hidden = num_hidden\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = Neural_Net(num_input, num_output, num_hidden).to(self.device)\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "        self.max_iters = max_iters\n",
    "        self.path_root = 'ANN_model/'\n",
    "    \n",
    "    def train(self, X: np.array, y: np.array):\n",
    "        x_train_ = torch.from_numpy(X).to(self.device)\n",
    "        y_train_ = torch.from_numpy(y).to(self.device)\n",
    "        self.model.train()\n",
    "        optim = torch.optim.Adam(self.model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optim, 2e4, gamma=0.1, last_epoch=-1)\n",
    "        for i in range(self.max_iters):\n",
    "            output = self.model(x_train_)\n",
    "            loss = self.loss_func(output, y_train_)\n",
    "            if loss.cpu().detach().numpy() < 1e-6:\n",
    "                print(\"early stop\")\n",
    "                break\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            if i % 10000 == 0:\n",
    "                print('steps: {}, loss: {}'.format(i, loss.cpu().detach().numpy()))\n",
    "            scheduler.step()\n",
    "\n",
    "    def predict(self, X: np.array):\n",
    "        self.model.eval()\n",
    "        x_test = torch.from_numpy(X).to(self.device)\n",
    "        output = self.model(x_test).cpu().detach().numpy()\n",
    "        return output\n",
    "    \n",
    "    def save_model(self, k1, k2):\n",
    "        PATH = self.path_root + \"ANN_{}_{}_{}.pt\".format(k1, k2, self.num_hidden)\n",
    "        torch.save(self.model.state_dict(), PATH)\n",
    "    \n",
    "    def load_model(self, k1, k2):\n",
    "        PATH = self.path_root + \"ANN_{}_{}_{}.pt\".format(k1, k2, self.num_hidden)\n",
    "        self.model = Neural_Net(self.num_input, self.num_output, self.num_hidden).to(self.device)\n",
    "        self.model.load_state_dict(torch.load(PATH))\n",
    "        \n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ANN(X.shape[1], 1, 64, 10000)\n",
    "# model.load_model(0,0)\n",
    "# model.train(X, y)\n",
    "# model.save_model(0, 0)\n",
    "# output = model.predict(X)\n",
    "# error = torch.nn.MSELoss()(torch.from_numpy(output).to(device), torch.from_numpy(y.reshape((-1))).to(device))\n",
    "# error = error.cpu().detach().numpy()\n",
    "# print(\"ANN Model error: {}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "params = {}\n",
    "params['Linear_Regression'] = {'lambda': [1.0, 1e-1, 1e-2, 1e-3]}\n",
    "params['Baseline'] = [None]\n",
    "params['ANN'] = {'hidden_layer_sizes': [1, 16, 64]}\n",
    "\n",
    "def twolevelcv_reg(X: np.array, y: np.array, k1: int, k2: int, rs: int, params: dict):\n",
    "    loss_func = nn.MSELoss()\n",
    "    k_1 = 0\n",
    "    names = [n for n in params.keys()]\n",
    "    col_names = ['Param. Value', 'Error']\n",
    "    df = dataset_creator(names, col_names, k1)\n",
    "    kf1 = KFold(n_splits=k1)\n",
    "    # first level split\n",
    "    for train_idx1, test_idx1 in kf1.split(X, y):\n",
    "        k_1 += 1\n",
    "        kf2 = KFold(n_splits=k2)\n",
    "        print(f'Computing KFold {k_1}/{k1}...')\n",
    "        # second level split\n",
    "        k_2 = 0\n",
    "        for train_idx2, test_idx2 in tqdm(kf2.split(X[train_idx1, :], y[train_idx1]), total = k2):\n",
    "            k_2 += 1\n",
    "            X_train = X[train_idx2, :]\n",
    "            y_train = y[train_idx2]\n",
    "            X_test = X[test_idx2, :]\n",
    "            y_test = y[test_idx2]\n",
    "            generalization_error_test_x = X[test_idx1, :]\n",
    "            generalization_error_test_y = y[test_idx1]\n",
    "            for name in names:\n",
    "                if name == 'Linear_Regression':\n",
    "                    error_test = []\n",
    "                    for i in params[name]['lambda']:\n",
    "                        model = lm.Ridge(alpha = i, fit_intercept=True)\n",
    "                        model = model.fit(X_train, y_train)\n",
    "                        # Compute model output:\n",
    "                        y_est = model.predict(X_test)\n",
    "                        error = nn.MSELoss()(torch.from_numpy(y_test.reshape((-1))).to(device), \\\n",
    "                                            torch.from_numpy(y_est.reshape((-1))).to(device))\n",
    "                        error = error.cpu().detach().numpy()\n",
    "                        error_test.append(error)\n",
    "                    min_param = params[name]['lambda'][np.argmin(error_test)]\n",
    "                elif name == 'ANN':\n",
    "                    error_test = []\n",
    "                    for i in params[name]['hidden_layer_sizes']:\n",
    "                        ANN_model = ANN(X_train.shape[1], 1, i, int(1e5))\n",
    "                        ANN_model.load_model(k_1, k_2)\n",
    "                        ANN_model.train(X_train, y_train)\n",
    "                        ANN_model.save_model(k_1, k_2)\n",
    "                        output = ANN_model.predict(X_test)\n",
    "                        error = loss_func(torch.from_numpy(output).to(device), torch.from_numpy(y_test.reshape((-1))).to(device))\n",
    "                        error = error.cpu().detach().numpy()\n",
    "                        error_test.append(error)\n",
    "                        print(\"ANN Model error: {}\".format(error))\n",
    "                    min_param = params[name]['hidden_layer_sizes'][np.argmin(error_test)]\n",
    "                else:\n",
    "                    model = DummyRegressor(strategy=\"mean\")\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    error = nn.MSELoss()(torch.from_numpy(y_test.reshape((-1))).to(device), \\\n",
    "                        torch.from_numpy(y_pred.reshape((-1))).to(device))\n",
    "                    error = error.cpu().detach().numpy()\n",
    "                    error_test = error\n",
    "                    min_param = np.NaN\n",
    "                df.loc(axis = 1)[name, 'Error'][k_1] = np.min(error_test)\n",
    "                df.loc(axis = 1)[name, 'Param. Value'][k_1] = min_param\n",
    "                \n",
    "    return df, test_idx1\n",
    "\n",
    "# Table, test_set_outer = twolevelcv_reg(X, y, 5, 5, 1, params)\n",
    "# Table.to_csv('Results/Regression.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2 Generalization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import joblib\n",
    "params = {}\n",
    "params['Linear_Regression'] = {'lambda': [1.0, 1e-1, 1e-2, 1e-3]}\n",
    "params['Baseline'] = [None]\n",
    "params['ANN'] = {'hidden_layer_sizes': [1, 16, 64]}\n",
    "\n",
    "def twolevelcv_reg_generalization_error(X: np.array, y: np.array, k1: int, k2: int, rs: int, params: dict):\n",
    "    loss_func = nn.MSELoss()\n",
    "    k_1 = 0\n",
    "    names = [n for n in params.keys()]\n",
    "    col_names = ['Param. Value', 'Error', 'Generalization Error']\n",
    "    df = dataset_creator(names, col_names, k1)\n",
    "    kf1 = KFold(n_splits=k1)\n",
    "    # first level split\n",
    "    for train_idx1, test_idx1 in kf1.split(X, y):\n",
    "        k_1 += 1\n",
    "        kf2 = KFold(n_splits=k2)\n",
    "        print(f'Computing KFold {k_1}/{k1}...')\n",
    "        # second level split\n",
    "        k_2 = 0\n",
    "        for train_idx2, test_idx2 in tqdm(kf2.split(X[train_idx1, :], y[train_idx1]), total = k2):\n",
    "            k_2 += 1\n",
    "            X_train = X[train_idx2, :]\n",
    "            y_train = y[train_idx2]\n",
    "            X_test = X[test_idx2, :]\n",
    "            y_test = y[test_idx2]\n",
    "            generalization_error_test_x = X[test_idx1, :]\n",
    "            generalization_error_test_y = y[test_idx1]\n",
    "            for name in names:\n",
    "                if name == 'Linear_Regression':\n",
    "                    error_test = []\n",
    "                    gen_error_test = []\n",
    "                    for i in params[name]['lambda']:\n",
    "                        model = lm.Ridge(alpha = i, fit_intercept=True)\n",
    "                        model = model.fit(X_train, y_train)\n",
    "                        joblib.dump(model, \"Linear_Regression/LR_{}_{}_{}.pkl\".format(k_1, k_2, i))\n",
    "                        # Compute model output:\n",
    "                        y_est = model.predict(X_test)\n",
    "                        error = nn.MSELoss()(torch.from_numpy(y_test.reshape((-1))).to(device), \\\n",
    "                                            torch.from_numpy(y_est.reshape((-1))).to(device))\n",
    "                        error = error.cpu().detach().numpy()\n",
    "                        error_test.append(error)\n",
    "                        gen_test_y = model.predict(generalization_error_test_x)\n",
    "                        gen_error = nn.MSELoss()(torch.from_numpy(generalization_error_test_y.reshape((-1))).to(device), \\\n",
    "                                            torch.from_numpy(gen_test_y.reshape((-1))).to(device))\n",
    "                        gen_error = gen_error.cpu().detach().numpy()\n",
    "                        gen_error_test.append(gen_error)\n",
    "                    min_param = params[name]['lambda'][np.argmin(error_test)]\n",
    "                    gen_error_out = gen_error_test[np.argmin(error_test)]\n",
    "                    error_out = error_test[np.argmin(error_test)]\n",
    "                elif name == 'ANN':\n",
    "                    error_test = []\n",
    "                    gen_error_test = []\n",
    "                    for i in params[name]['hidden_layer_sizes']:\n",
    "                        ANN_model = ANN(X_train.shape[1], 1, i, int(1e5))\n",
    "                        ANN_model.load_model(k_1, k_2)\n",
    "                        # ANN_model.train(X_train, y_train)\n",
    "                        # ANN_model.save_model(k_1, k_2)\n",
    "                        output = ANN_model.predict(X_test)\n",
    "                        error = loss_func(torch.from_numpy(output).to(device), torch.from_numpy(y_test.reshape((-1))).to(device))\n",
    "                        error = error.cpu().detach().numpy()\n",
    "                        error_test.append(error)\n",
    "                        gen_test_y = model.predict(generalization_error_test_x)\n",
    "                        gen_error = nn.MSELoss()(torch.from_numpy(generalization_error_test_y.reshape((-1))).to(device), \\\n",
    "                                            torch.from_numpy(gen_test_y.reshape((-1))).to(device))\n",
    "                        gen_error = gen_error.cpu().detach().numpy()\n",
    "                        gen_error_test.append(gen_error)\n",
    "                    min_param = params[name]['hidden_layer_sizes'][np.argmin(error_test)]\n",
    "                    gen_error_out = gen_error_test[np.argmin(error_test)]\n",
    "                    error_out = error_test[np.argmin(error_test)]\n",
    "                else:\n",
    "                    model = DummyRegressor(strategy=\"mean\")\n",
    "                    model.fit(X_train, y_train)\n",
    "                    joblib.dump(model, \"BaseLine/BL_{}_{}.pkl\".format(k_1, k_2))\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    error = nn.MSELoss()(torch.from_numpy(y_test.reshape((-1))).to(device), \\\n",
    "                        torch.from_numpy(y_pred.reshape((-1))).to(device))\n",
    "                    error = error.cpu().detach().numpy()\n",
    "                    error_test = error\n",
    "                    gen_test_y = model.predict(generalization_error_test_x)\n",
    "                    gen_error = nn.MSELoss()(torch.from_numpy(generalization_error_test_y.reshape((-1))).to(device), \\\n",
    "                                            torch.from_numpy(gen_test_y.reshape((-1))).to(device))\n",
    "                    gen_error = gen_error.cpu().detach().numpy()\n",
    "                    min_param = np.NaN\n",
    "                    gen_error_out = gen_error_test[np.argmin(error_test)]\n",
    "                    error_out = error\n",
    "                df.loc(axis = 1)[name, 'Error'][k_1] = error_out\n",
    "                df.loc(axis = 1)[name, 'Param. Value'][k_1] = min_param\n",
    "                df.loc(axis = 1)[name, 'Generalization Error'][k_1] = gen_error_out\n",
    "                \n",
    "    return df, test_idx1\n",
    "\n",
    "# Table, test_set_outer = twolevelcv_reg_generalization_error(X, y, 5, 5, 1, params)\n",
    "# Table.to_csv('Results/Regression_Generalization_Error.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sectin 3 Compare of different models using Setup 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P-value and Confidencial Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "mA = joblib.load('Linear_Regression/LR_1_1_0.001.pkl')\n",
    "mB = joblib.load('BaseLine/BL_1_1.pkl')\n",
    "yhatA = mA.predict(X)\n",
    "yhatB = mB.predict(X)\n",
    "yhatB = np.reshape(yhatB, (-1,1))\n",
    "def P_value_CI(mA, mB, X, y):\n",
    "    yhatA = mA.predict(X)\n",
    "    yhatA = np.reshape(yhatA, (-1,1))\n",
    "    yhatB = mB.predict(X)\n",
    "    yhatB = np.reshape(yhatB, (-1,1))\n",
    "    zA = np.abs(y - yhatA ) ** 2\n",
    "\n",
    "    # compute confidence interval of model A\n",
    "    alpha = 0.05\n",
    "    CIA = st.t.interval(1-alpha, df=len(zA)-1, loc=np.mean(zA), scale=st.sem(zA))  # Confidence interval\n",
    "\n",
    "    # Compute confidence interval of z = zA-zB and p-value of Null hypothesis\n",
    "    zB = np.abs(y - yhatB ) ** 2\n",
    "    z = zA - zB\n",
    "    CI = st.t.interval(1-alpha, len(z)-1, loc=np.mean(z), scale=st.sem(z))  # Confidence interval\n",
    "    p = 2*st.t.cdf( -np.abs( np.mean(z) )/st.sem(z), df=len(z)-1)  # p-value\n",
    "    s, p = st.ttest_rel(yhatA, yhatB)\n",
    "    return p, CI, s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paired T test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 38.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 2/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 52.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 57.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 49.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 68.22it/s]\n"
     ]
    }
   ],
   "source": [
    "def Models_comparison(X: np.array, y: np.array, k1: int, k2: int, rs: int, params: dict):\n",
    "    loss_func = nn.MSELoss()\n",
    "    k_1 = 0\n",
    "    names = ['LR vs NN', 'LR vs BL', 'NN vs BL']\n",
    "    col_names = ['t-test', 'p-value', 'Confidenctial Interval']\n",
    "    df = dataset_creator(names, col_names, k1)\n",
    "    kf1 = KFold(n_splits=k1)\n",
    "    # first level split\n",
    "    for train_idx1, test_idx1 in kf1.split(X, y):\n",
    "        k_1 += 1\n",
    "        kf2 = KFold(n_splits=k2)\n",
    "        print(f'Computing KFold {k_1}/{k1}...')\n",
    "        # second level split\n",
    "        k_2 = 0\n",
    "        for train_idx2, test_idx2 in tqdm(kf2.split(X[train_idx1, :], y[train_idx1]), total = k2):\n",
    "            k_2 += 1\n",
    "            X_train = X[train_idx2, :]\n",
    "            y_train = y[train_idx2]\n",
    "            X_test = X[test_idx2, :]\n",
    "            y_test = y[test_idx2]\n",
    "            generalization_error_test_x = X[test_idx1, :]\n",
    "            generalization_error_test_y = y[test_idx1]\n",
    "            model_NN = ANN(X_train.shape[1], 1, 64, int(1e5))\n",
    "            model_LR = joblib.load('Linear_Regression/LR_{}_{}_0.001.pkl'.format(k_1, k_2))\n",
    "            model_NN.load_model(k_1, k_2)\n",
    "            model_BL = joblib.load('BaseLine/BL_{}_{}.pkl'.format(k_1, k_2))\n",
    "            for name in names:\n",
    "                if name == 'LR vs NN':\n",
    "                    p, CI, stats = P_value_CI(model_LR, model_NN, generalization_error_test_x, generalization_error_test_y)\n",
    "                    df.loc(axis = 1)[name, 't-test'][k_1] = stats\n",
    "                    df.loc(axis = 1)[name, 'p-value'][k_1] = p\n",
    "                    df.loc(axis = 1)[name, 'Confidenctial Interval'][k_1] = CI\n",
    "                elif 'LR vs BL':\n",
    "                    p, CI, stats = P_value_CI(model_LR, model_BL, generalization_error_test_x, generalization_error_test_y)\n",
    "                    df.loc(axis = 1)[name, 't-test'][k_1] = stats\n",
    "                    df.loc(axis = 1)[name, 'p-value'][k_1] = p\n",
    "                    df.loc(axis = 1)[name, 'Confidenctial Interval'][k_1] = CI\n",
    "                else:\n",
    "                    p, CI, stats = P_value_CI(model_NN, model_BL, generalization_error_test_x, generalization_error_test_y)\n",
    "                    df.loc(axis = 1)[name, 't-test'][k_1] = stats\n",
    "                    df.loc(axis = 1)[name, 'p-value'][k_1] = p\n",
    "                    df.loc(axis = 1)[name, 'Confidenctial Interval'][k_1] = CI\n",
    "            \n",
    "    return df, test_idx1\n",
    "\n",
    "Table, test_set_outer = Models_comparison(X, y, 5, 5, 1, params)\n",
    "Table.to_csv('Results/Regression_P_value.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad43814",
   "metadata": {},
   "source": [
    "# **2 - Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying object without editing the original\n",
    "df_ = df.copy(deep=True)\n",
    "# Doing this we can choose to use outliers filter or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "· NUMBER OF FEATURES: 16\n",
      "\n",
      "· FEATURES: ['Area' 'Perimeter' 'MajorAxisLength' 'MinorAxisLength' 'AspectRation'\n",
      " 'Eccentricity' 'ConvexArea' 'EquivDiameter' 'Extent' 'Solidity'\n",
      " 'roundness' 'Compactness' 'ShapeFactor1' 'ShapeFactor2' 'ShapeFactor3'\n",
      " 'ShapeFactor4']\n",
      "\n",
      "· NUMBER OF DATA POINTS: 13611\n",
      "\n",
      "· CLASSES: ['SEKER' 'BARBUNYA' 'BOMBAY' 'CALI' 'HOROZ' 'SIRA' 'DERMASON']\n",
      "\n",
      "· NUMBER OF CLASSES: 7\n"
     ]
    }
   ],
   "source": [
    "columns = df_.columns.values\n",
    "X = df_.drop(columns='Class').values\n",
    "y = df_['Class']\n",
    "le = LabelEncoder()\n",
    "y_ = le.fit_transform(y)\n",
    "classes = y.unique()\n",
    "\n",
    "print('· NUMBER OF FEATURES:', X.shape[1])\n",
    "print('\\n· FEATURES:', columns[:-1])\n",
    "print('\\n· NUMBER OF DATA POINTS:', X.shape[0])\n",
    "print('\\n· CLASSES:', classes)\n",
    "print('\\n· NUMBER OF CLASSES:', len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Transformations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered outliers: 298\n"
     ]
    }
   ],
   "source": [
    "Threshold_ = 3\n",
    "outlier_index = []\n",
    "df_ = pd.DataFrame(columns=df.columns)\n",
    "index = 0\n",
    "for K in classes:\n",
    "    outlier_index = []\n",
    "    a = df.loc[df[\"Class\"] == K]\n",
    "    value = a.drop(columns='Class').values\n",
    "    for j in range(16):\n",
    "        std = np.std(value[:, j])\n",
    "        mean = np.mean(value[:, j])\n",
    "        for i in range(value[:, j].shape[0]):\n",
    "            if (value[i, j] - mean) / std > Threshold_:\n",
    "                outlier_index.append(i + index)\n",
    "    index = i + index + 1\n",
    "    outlier_index = np.unique(outlier_index)\n",
    "    a = a.drop(outlier_index)\n",
    "    df_ = pd.concat([df_,a])\n",
    "df_.reset_index(drop=True, inplace=True)\n",
    "print(f'Filtered outliers: {df.shape[0] - df_.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarization of the dataset\n",
    "sc = StandardScaler()\n",
    "X_stdz = sc.fit_transform(X)\n",
    "df_stdz = pd.DataFrame(columns = columns[:-1], data = X_stdz)\n",
    "df_stdz['Class'] = y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Logistic regression *vs.* Neural Network *vs.* Baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "random_state = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression(multi_class='multinomial', solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# # evaluate the model and collect the scores\n",
    "# n_scores = cross_val_score(model, X_stdz, y_, scoring = 'accuracy', cv=cv, n_jobs=-1)\n",
    "# # report the model performance\n",
    "# print('Mean Accuracy: %.3f (+-%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3 Cross-Validation table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 1/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:47<00:00, 40.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 2/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [07:13<00:00, 43.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 3/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [11:02<00:00, 66.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 4/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:52<00:00, 59.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 5/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:22<00:00, 62.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 6/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:14<00:00, 37.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 7/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [15:30<00:00, 93.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 8/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [12:31<00:00, 75.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 9/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:49<00:00, 64.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KFold 10/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [11:46<00:00, 70.62s/it]\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "lam = np.logspace(-6, 2, 100)\n",
    "C = 1/ lam\n",
    "# C = [200000000, 10000000, 0.1519911082952933, 0.2848035868435805 ]\n",
    "params['LogisticRegression'] = {'C': C}\n",
    "params['DummyClassifier'] = [None]\n",
    "params['MLPClassifier'] = {'hidden_layer_sizes': [(8, ), (16, ), (20, )]}\n",
    "models = [LogisticRegression(multi_class='multinomial', solver='saga', max_iter=1000000, random_state= random_state, tol = 0.003, n_jobs = -1),\n",
    "        DummyClassifier(strategy='most_frequent', random_state=random_state),\n",
    "        MLPClassifier(solver='adam', activation='logistic', alpha=1e-4, random_state=random_state, max_iter=1000, \n",
    "        early_stopping=True, validation_fraction=0.2, warm_start=True, verbose=False, learning_rate ='adaptive', learning_rate_init=0.01)]\n",
    "k1 = 10\n",
    "k2 = 10\n",
    "Table, test_set_outer = twolevelcv(X = X_stdz, y = y_, k1 = k1, k2 = k2, models = models, params = params, rs = random_state)\n",
    "Table.to_csv('Results/Test2_saga.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">LogisticRegression</th>\n",
       "      <th colspan=\"2\" halign=\"left\">DummyClassifier</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MLPClassifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Param. Value</th>\n",
       "      <th>Error</th>\n",
       "      <th>Param. Value</th>\n",
       "      <th>Error</th>\n",
       "      <th>Param. Value</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.040033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788399</td>\n",
       "      <td>(16,)</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.035102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78449</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.035102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.035102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78449</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.034286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.035102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78449</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.035918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.035102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78449</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.035918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.722081</td>\n",
       "      <td>0.036735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790204</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.040816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.722081</td>\n",
       "      <td>0.036735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790204</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.236449</td>\n",
       "      <td>0.033469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790204</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.041633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.236449</td>\n",
       "      <td>0.033469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790204</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.042449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.284804</td>\n",
       "      <td>0.041633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788571</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.044082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LogisticRegression           DummyClassifier           MLPClassifier  \\\n",
       "            Param. Value     Error    Param. Value     Error  Param. Value   \n",
       "KFold                                                                        \n",
       "1              1000000.0  0.040033             NaN  0.788399         (16,)   \n",
       "2              1000000.0  0.035102             NaN   0.78449          (8,)   \n",
       "3              1000000.0  0.035102             NaN   0.78449          (8,)   \n",
       "4              1000000.0  0.035102             NaN   0.78449          (8,)   \n",
       "5              1000000.0  0.035102             NaN   0.78449          (8,)   \n",
       "6               0.722081  0.036735             NaN  0.790204          (8,)   \n",
       "7               0.722081  0.036735             NaN  0.790204          (8,)   \n",
       "8               0.236449  0.033469             NaN  0.790204          (8,)   \n",
       "9               0.236449  0.033469             NaN  0.790204          (8,)   \n",
       "10              0.284804  0.041633             NaN  0.788571          (8,)   \n",
       "\n",
       "                 \n",
       "          Error  \n",
       "KFold            \n",
       "1      0.039216  \n",
       "2      0.035102  \n",
       "3      0.034286  \n",
       "4      0.035918  \n",
       "5      0.035918  \n",
       "6      0.040816  \n",
       "7          0.04  \n",
       "8      0.041633  \n",
       "9      0.042449  \n",
       "10     0.044082  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table = Table.round(3)\n",
    "Table.to_csv(r'Results\\Table_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1361,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_outer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.4 Stadistical Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def McNemar(models: list, X: np.array, y: np.array, k1: int, rs: int):\n",
    "    \"\"\"Computes the McNemar matrix for all the models in the list \n",
    "\n",
    "    Args:\n",
    "        models (list): list of models\n",
    "        X (np.array): Features\n",
    "        y (np.array): Classes\n",
    "        k1 (int): Number of folds\n",
    "        rs (int): Random state\n",
    "\n",
    "    Returns:\n",
    "        _type_: Matrix as a dictionary\n",
    "    \"\"\"\n",
    "    kf1 = StratifiedKFold(k1, shuffle = True, random_state=rs)\n",
    "    k = 0\n",
    "    # setting up all the possible combinations between the different models\n",
    "    matrix = dict.fromkeys(combinations(range(len(models)), 2))\n",
    "    matrix_tot = dict.fromkeys(combinations(range(len(models)), 2))\n",
    "    for train_idx, test_idx in kf1.split(X, y):\n",
    "        test_size = test_idx.shape[0]\n",
    "        yABC = np.empty(shape=(len(models), test_size))\n",
    "        for i, model in enumerate(models):\n",
    "            model.fit(X[train_idx,:], y[train_idx])\n",
    "            y_pred = model.predict(X[test_idx, :])\n",
    "            yABC[i, :] = 1*(y_pred == y[test_idx])\n",
    "        for j in list(matrix.keys()):\n",
    "            if k == 0:\n",
    "                matrix[j] = np.empty(shape=(k1, 4))\n",
    "            n11 = np.sum(yABC[j[0],:]*yABC[j[1],:])\n",
    "            n12 = np.sum(yABC[j[0],:]*(1-yABC[j[1],:]))\n",
    "            n21 = np.sum(yABC[j[1],:]*(1-yABC[j[0],:]))\n",
    "            n22 = np.sum((1-yABC[0,:])*(1-yABC[1,:]))\n",
    "            matrix[j][k] = np.array([n11, n12, n21, n22])\n",
    "            matrix_tot[j] = matrix[j].sum(axis = 0)\n",
    "        k+=1\n",
    "    return matrix, matrix_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1\n",
    "models = [LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state= random_state, C = 0.07),\n",
    "        DummyClassifier(strategy='most_frequent', random_state=random_state),\n",
    "        MLPClassifier(solver='adam', activation='logistic', alpha=1e-4, random_state=random_state, max_iter=1000, hidden_layer_sizes=(8, ),\n",
    "        early_stopping=True, validation_fraction=0.2, warm_start=True, verbose=False, learning_rate ='adaptive', learning_rate_init=0.01)]\n",
    "k1 = 10\n",
    "mfull, m_tot = McNemar(models, X_stdz[test_set_outer, :], y_[test_set_outer], k1, rs = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           (0, 1)\n",
      "       [34. 92.  2.  9.]\n",
      "       [34. 93.  1.  8.]\n",
      "       [32. 92.  3.  9.]\n",
      "       [35. 91.  0. 10.]\n",
      "       [34. 98.  1.  3.]\n",
      "       [34. 84.  1. 17.]\n",
      "       [31. 93.  5.  7.]\n",
      "       [33. 96.  3.  4.]\n",
      "       [31. 93.  5.  7.]\n",
      "       [32. 94.  4.  6.]\n",
      "\n",
      "Total: [330. 926.  25.  80.]\n",
      "----------------------------------\n",
      "           (0, 2)\n",
      "       [121.   5.   2.   9.]\n",
      "       [121.   6.   2.   8.]\n",
      "       [123.   1.   2.   9.]\n",
      "       [124.   2.   2.  10.]\n",
      "       [128.   4.   0.   3.]\n",
      "       [113.   5.   2.  17.]\n",
      "       [123.   1.   1.   7.]\n",
      "       [128.   1.   1.   4.]\n",
      "       [123.   1.   5.   7.]\n",
      "       [124.   2.   1.   6.]\n",
      "\n",
      "Total: [1228.   28.   18.   80.]\n",
      "----------------------------------\n",
      "           (1, 2)\n",
      "       [32.  4. 91.  9.]\n",
      "       [33.  2. 90.  8.]\n",
      "       [32.  3. 93.  9.]\n",
      "       [34.  1. 92. 10.]\n",
      "       [34.  1. 94.  3.]\n",
      "       [33.  2. 82. 17.]\n",
      "       [31.  5. 93.  7.]\n",
      "       [32.  4. 97.  4.]\n",
      "       [32.  4. 96.  7.]\n",
      "       [31.  5. 94.  6.]\n",
      "\n",
      "Total: [324.  31. 922.  80.]\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for mat in mfull:\n",
    "    print('          ',mat)\n",
    "    for ma in mfull[mat]:\n",
    "        print('      ', ma)\n",
    "    print('\\nTotal:',m_tot[mat])\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the matrix with shape (3: number of models, 10: nº of k-folds, 4: matrix shape)\n",
    "\n",
    "The matrix is squeezed so we have:\n",
    "$$\\begin{bmatrix}\n",
    " n_{11}    & n_{12}  \\\\\n",
    " n_{21}    & n_{22}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Here is $[ n_{11}, n_{12}, n_{21}, n_{22} ]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0:$ Model A has the same performarnce as model B \n",
    "\n",
    "$H_1:$ Model A and model B has different performance\n",
    "\n",
    "small p_value-> we discard H0 -> Model A and Model B have different performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we set:\n",
    "\n",
    "**Model 0**: LR\n",
    "\n",
    "**Model 1**: Baseline\n",
    "\n",
    "**Model 2**: MLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***P-Values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "combs = list(combinations(range(len(models)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Diego\\Documents\\DTU\\IntroML\\Project1_ML\\Project2.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Diego/Documents/DTU/IntroML/Project1_ML/Project2.ipynb#X56sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pv_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m\u001b[39m.\u001b[39mfromkeys(combs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Diego/Documents/DTU/IntroML/Project1_ML/Project2.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m combs:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Diego/Documents/DTU/IntroML/Project1_ML/Project2.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     vals \u001b[39m=\u001b[39m m[j][:, \u001b[39m1\u001b[39m:\u001b[39m3\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Diego/Documents/DTU/IntroML/Project1_ML/Project2.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     pv_dict[j] \u001b[39m=\u001b[39m [binom\u001b[39m.\u001b[39mcdf(\u001b[39mmin\u001b[39m(vals[i]), n \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(vals[i]), p \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(vals))]\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "pv_dict = dict.fromkeys(combs)\n",
    "for j in combs:\n",
    "    vals = m[j][:, 1:3]\n",
    "    pv_dict[j] = [binom.cdf(min(vals[i]), n = sum(vals[i]), p = 1/2) for i in range(len(vals))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "McNemar_pv = pd.DataFrame(columns = combs, index = range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n",
      "$2.25·10^{-25}$\n",
      "$4.80·10^{-27}$\n",
      "$3.61·10^{-24}$\n",
      "$4.04·10^{-28}$\n",
      "$1.58·10^{-28}$\n",
      "$2.22·10^{-24}$\n",
      "$2.26·10^{-22}$\n",
      "$2.55·10^{-25}$\n",
      "$2.26·10^{-22}$\n",
      "$1.19·10^{-23}$\n",
      "(0, 2)\n",
      "$2.27·10^{-01}$\n",
      "$1.45·10^{-01}$\n",
      "$5.00·10^{-01}$\n",
      "$6.88·10^{-01}$\n",
      "$6.25·10^{-02}$\n",
      "$2.27·10^{-01}$\n",
      "$7.50·10^{-01}$\n",
      "$7.50·10^{-01}$\n",
      "$1.09·10^{-01}$\n",
      "$5.00·10^{-01}$\n",
      "(1, 2)\n",
      "$8.40·10^{-23}$\n",
      "$8.64·10^{-25}$\n",
      "$1.86·10^{-24}$\n",
      "$9.49·10^{-27}$\n",
      "$2.42·10^{-27}$\n",
      "$1.85·10^{-22}$\n",
      "$2.26·10^{-22}$\n",
      "$1.68·10^{-24}$\n",
      "$3.22·10^{-24}$\n",
      "$1.19·10^{-22}$\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for n in pv_dict.values():\n",
    "    print(f'{combs[i]}')\n",
    "    for j, k in enumerate(n):\n",
    "        McNemar_pv[combs[i]][j] = \"{:.3e}\".format(k)\n",
    "        text = str(\"${:.2e}\".format(k))\n",
    "        text = text + '}$'\n",
    "        text = text.replace(\"e\", \"·10^{\")\n",
    "        print(text)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "McNemar_pv.to_csv('Results/McNemar_pv_best.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcs(mat: np.array):\n",
    "    \"\"\"Calculate f y g from a McNemar Matrix\n",
    "    Args:\n",
    "        matrix (np.array): McNemar matrix from one K-fold\n",
    "    Returns:\n",
    "        _type_: f and g\n",
    "    \"\"\"\n",
    "    n = mat.sum()\n",
    "    n12 = mat[1]\n",
    "    n21 = mat[2]\n",
    "    E_th = (n12 - n21)/n \n",
    "    Q = (n**2 * (n+1) * (E_th +1) * (1-E_th)) / (n * (n12 + n21) - (n12 - n21)**2)\n",
    "    f = (Q-1)*(E_th+1)/2\n",
    "    g = (Q-1)*(1-E_th)/2\n",
    "    return f, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval(mat: np.array, alpha: float):\n",
    "    \"\"\"McNemar confidence interval\n",
    "\n",
    "    Args:\n",
    "        alpha (float): The desired confidence (should be 0.05)  \n",
    "        f (_type_): output of calcs\n",
    "        g (_type_): output of calcs \n",
    "\n",
    "    Returns:\n",
    "        _type_: left and right bounds from the interval\n",
    "    \"\"\"\n",
    "    f,g = calcs(mat)\n",
    "    theta_L = 2*beta.ppf(alpha, f, g) - 1\n",
    "    theta_R = 2*beta.ppf(1 - alpha/2, f, g) - 1\n",
    "    return theta_L, theta_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n",
      "[0.58, 0.74]\n",
      "[0.61, 0.75]\n",
      "[0.58, 0.74]\n",
      "[0.6, 0.74]\n",
      "[0.64, 0.79]\n",
      "[0.54, 0.69]\n",
      "[0.57, 0.73]\n",
      "[0.61, 0.76]\n",
      "[0.57, 0.73]\n",
      "[0.58, 0.75]\n",
      "(0, 2)\n",
      "[-0.01, 0.06]\n",
      "[-0.0, 0.07]\n",
      "[-0.03, 0.02]\n",
      "[-0.02, 0.03]\n",
      "[0.01, 0.06]\n",
      "[-0.01, 0.06]\n",
      "[-0.02, 0.02]\n",
      "[-0.02, 0.02]\n",
      "[-0.06, 0.01]\n",
      "[-0.01, 0.03]\n",
      "(1, 2)\n",
      "[-0.71, -0.55]\n",
      "[-0.73, -0.57]\n",
      "[-0.73, -0.57]\n",
      "[-0.73, -0.58]\n",
      "[-0.77, -0.62]\n",
      "[-0.67, -0.51]\n",
      "[-0.72, -0.55]\n",
      "[-0.75, -0.59]\n",
      "[-0.73, -0.57]\n",
      "[-0.73, -0.56]\n"
     ]
    }
   ],
   "source": [
    "for i in m:\n",
    "    print(i)\n",
    "    for mat in m[i]:\n",
    "        theta_L, theta_R = interval(mat, 0.05)\n",
    "        print(f'[{np.round(theta_L, 2)}, {np.round(theta_R, 2)}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.5 Train logistic regression model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the fourth exercise do we have to repeat the parameter selection process or can just go ahead with the best parameter selection for each model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ca68e7b73839bd75b2d076de248efc7bf9c399b12d8560f2d058acabfd392b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
